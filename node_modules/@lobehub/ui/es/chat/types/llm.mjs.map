{"version":3,"file":"llm.mjs","names":[],"sources":["../../../src/chat/types/llm.ts"],"sourcesContent":["/**\n * LLM 模型\n */\nexport enum LanguageModel {\n  /**\n   * GPT 3.5 Turbo\n   */\n  GPT3_5 = 'gpt-3.5-turbo',\n  GPT3_5_16K = 'gpt-3.5-turbo-16k',\n  /**\n   * GPT 4\n   */\n  GPT4 = 'gpt-4',\n  GPT4_32K = 'gpt-4-32k',\n}\n\n// 语言模型的设置参数\nexport interface LLMParams {\n  /**\n   * 控制生成文本中的惩罚系数，用于减少重复性\n   * @default 0\n   */\n  frequency_penalty?: number;\n  /**\n   * 生成文本的最大长度\n   */\n  max_tokens?: number;\n  /**\n   * 控制生成文本中的惩罚系数，用于减少主题的变化\n   * @default 0\n   */\n  presence_penalty?: number;\n  /**\n   * 生成文本的随机度量，用于控制文本的创造性和多样性\n   * @default 0.6\n   */\n  temperature?: number;\n  /**\n   * 控制生成文本中最高概率的单个 token\n   * @default 1\n   */\n  top_p?: number;\n}\n\nexport type LLMRoleType = 'user' | 'system' | 'assistant' | 'function';\n\nexport interface LLMMessage {\n  content: string;\n  role: LLMRoleType;\n}\n\nexport type LLMExample = LLMMessage[];\n"],"mappings":";;;;AAGA,IAAY,0DAAL;;;;AAIL;AACA;;;;AAIA;AACA"}